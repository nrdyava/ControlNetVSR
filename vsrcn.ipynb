{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53875089-4755-45c2-a396-13f0ff97f0b3",
   "metadata": {},
   "source": [
    "## Import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6513c3fd-4af4-4490-88dd-00c0da2a63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import requests\n",
    "from transformers import AutoTokenizer, PretrainedConfig, CLIPTextModel, CLIPImageProcessor\n",
    "import diffusers\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    ControlNetModel,\n",
    "    DDPMScheduler,\n",
    "    StableDiffusionControlNetPipeline, \n",
    "    StableDiffusionControlNetImg2ImgPipeline,\n",
    "    UNet2DConditionModel,\n",
    "    UniPCMultistepScheduler,\n",
    ")\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionUpscalePipeline\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c2bf1-c14c-44ce-be0b-647b8ebbc5be",
   "metadata": {},
   "source": [
    "## Dataset & Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe1a5970-e3ad-4245-9da9-749f27018c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_dataset(Dataset):\n",
    "    def __init__(self, train_dir, temporal_radius = 1):\n",
    "        self.train_dir = train_dir\n",
    "        self.temporal_radius = temporal_radius\n",
    "        self.video_names = os.listdir(os.path.join(train_dir, \"train_sharp\"))\n",
    "        self.eligible_frames = [i for i in range(self.temporal_radius, 100-self.temporal_radius)]\n",
    "        self.n_videos = len(self.video_names)\n",
    "        self.n_eligible_frames = len(self.eligible_frames)\n",
    "        self.n_total_eligible_images = self.n_videos * self.n_eligible_frames\n",
    "        \n",
    "        self.lr_h_bound = 180 - 128\n",
    "        self.lr_w_bound = 320 - 128\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_total_eligible_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid_name = '{:03d}'.format(idx//self.n_eligible_frames)\n",
    "        frame_name = '{:08d}.png'.format(self.temporal_radius + idx%self.n_eligible_frames)\n",
    "        hr_frame = os.path.join(self.train_dir, \"train_sharp\", vid_name, frame_name)\n",
    "        lr_frame = os.path.join(self.train_dir, \"train_sharp_bicubic\", \"X4\", vid_name, frame_name)\n",
    "\n",
    "        hr_img = torchvision.io.read_image(hr_frame)\n",
    "        lr_img = torchvision.io.read_image(lr_frame)\n",
    "\n",
    "        ## Random Crop\n",
    "        x = random.randint(0, self.lr_h_bound)\n",
    "        y = random.randint(0, self.lr_w_bound)\n",
    "\n",
    "        hr_img = hr_img[:, x*4:(x*4)+512, y*4:y*4+512]\n",
    "        lr_img = lr_img[:, x:x+128, y:y+128]\n",
    "        \n",
    "        return {'hr_img': hr_img, \"lr_img\": lr_img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fda0cb9-a217-455c-9476-7f87ecb8809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_dataset(train_dir = \"data/train\", temporal_radius = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47be336e-1e03-49bb-a3b0-b713395e5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32ea1425-dcaa-4f5c-867b-9a1417a7ab4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx: 0\n",
      "hr_frame: torch.Size([3, 3, 512, 512])\n",
      "lr_frame: torch.Size([3, 3, 128, 128])\n",
      "\n",
      "\n",
      "batch_idx: 1\n",
      "hr_frame: torch.Size([3, 3, 512, 512])\n",
      "lr_frame: torch.Size([3, 3, 128, 128])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    print(\"batch_idx: {}\".format(batch_idx))\n",
    "    print(\"hr_frame: {}\".format(batch['hr_img'].shape))\n",
    "    print(\"lr_frame: {}\".format(batch['lr_img'].shape))\n",
    "    print(\"\\n\")\n",
    "    if (i==2):\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e896f7a-f5a0-45ca-9eec-039d8ecce3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfed5f0-e928-47eb-91c7-75a5d7d76e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b2b11c-9a77-44e2-ab26-3236e0f0691f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/train/train_sharp/032/00000062.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "Image.read(\"data/train/train_sharp/032/00000062.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d255dff-e60f-4690-9f40-4d9ac417f468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecbb33dc-952b-47f7-8a59-bb9d9db4c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torchvision.io.read_image(\"data/train/train_sharp/032/00000062.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1ae1a8-9fe4-422f-b1d5-2fed083d0ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 720, 1280])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff3994-dacb-45a1-8ba7-1e9e37a3990d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be8f4e5-3d1d-4e3d-a35d-ec59215a325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = torchvision.io.read_image(\"data/train/train_sharp_bicubic/X4/032/00000062.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28691ee-4981-420b-8982-7c00e5481da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 180, 320])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336d319-7f21-471c-bc2c-8be4b83a3101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba0995-4c33-44bb-9247-f61bbe50d0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f1fe5b4-b5ad-486d-b926-eee1c8b04995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "180-128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ac9b533-1bd8-4289-9ffe-1bcc2c882def",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_h_bound = 180 - 128\n",
    "lr_w_bound = 320 - 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33fdbcce-d961-4fd9-9bef-ed1d5f2b2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random.randint(0, lr_h_bound)\n",
    "y = random.randint(0, lr_w_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45040718-5e22-453e-b386-976c3a4b4dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2156c020-99b9-4d9e-b636-9c739fd8af96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2[:, x:x+128, y:y+128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8d32c89-ed68-484c-ad96-2b12c35e9cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, x*4:(x*4)+512, y*4:y*4+512].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e90fa-eea5-47f1-814f-7020e723926c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a48472-d388-46b9-9b6b-69272323be2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39cf04-135f-4014-a1e0-67c7b369e8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd3fdc93-5d59-4c5d-91c3-85901599d3ff",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec228d15-2c85-4d41-8b4b-22fa3ec19b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 13.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# load model and scheduler\n",
    "model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
    "pipeline = StableDiffusionUpscalePipeline.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a327cb9e-46e8-46ee-952b-3b56f686219d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StableDiffusionUpscalePipeline {\n",
       "  \"_class_name\": \"StableDiffusionUpscalePipeline\",\n",
       "  \"_diffusers_version\": \"0.28.0.dev0\",\n",
       "  \"_name_or_path\": \"stabilityai/stable-diffusion-x4-upscaler\",\n",
       "  \"feature_extractor\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"low_res_scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"DDPMScheduler\"\n",
       "  ],\n",
       "  \"max_noise_level\": 350,\n",
       "  \"safety_checker\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"DDIMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ],\n",
       "  \"watermarker\": [\n",
       "    null,\n",
       "    null\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a877d-9b67-4932-878d-3d25296194ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7cd17c6-67d4-40bf-85ab-38da339310b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-x4-upscaler\",\n",
    "    subfolder=\"tokenizer\"\n",
    ")\n",
    "scheduler = DDPMScheduler.from_pretrained(\"stabilityai/stable-diffusion-x4-upscaler\", subfolder=\"scheduler\")\n",
    "text_encoder_cls = CLIPTextModel\n",
    "text_encoder_cls\n",
    "text_encoder = text_encoder_cls.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-x4-upscaler\", subfolder=\"text_encoder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6e26a-9748-4b6c-90b8-8a9cb1feebd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f437bdc-62a8-4103-a97b-6f6a42f8907d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f18fcc-587e-4d02-8516-ed30beb3f90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 77, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = [\"\"]\n",
    "inputs = tokenizer(\n",
    "    captions, max_length=tokenizer.model_max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "encoder_hidden_states = text_encoder(inputs.input_ids, return_dict=False)[0]\n",
    "encoder_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb8d83b0-ad75-4e91-971f-76f2312861a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([410])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (1,))\n",
    "timesteps = timesteps.long()\n",
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2917bcb6-4aff-4d1f-9094-dab1f5d54f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78a431-2a98-4959-972c-6ab82f05c6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bacf4506-b0a8-41ed-b1c7-def6fda73397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.zeros((1, 3, 512, 512)).to(weight_dtype)\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a020703-6f68-4e7f-9068-5d5733746448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf7e5cbb-e2b4-41cf-af4a-d61a3b76ddb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_out = pipeline.vae.encode(inp).latent_dist.sample()\n",
    "vae_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1cb2b5-9604-4390-9825-e788e6abcf0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3827625a-91bc-49d1-98b5-318024051bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 128, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_out_ = torch.zeros((1, 7, 128, 128)).to(weight_dtype)\n",
    "vae_out_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b69648-31f6-4935-a460-e23e314ffccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e59bcd09-9c20-434b-94a3-cff954c9d6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_out = pipeline.unet(vae_out_, timesteps, encoder_hidden_states, class_labels = torch.zeros(1).to(torch.int))\n",
    "unet_out.sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996b69f-fa0c-4b19-8f0e-f664e1335539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c877892b-4ca2-4042-8bae-a09f4340418e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pipeline.vae.decode(unet_out.sample)\n",
    "out.sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023a287b-f4be-4caa-af03-016330169c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39087e58-f576-4dcd-95c3-9527268d5306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a152de-ffd7-4a28-b957-21195fecc27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8028a97d-1d97-4b0f-b6a1-b63af71137bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8dcdf6-7f1c-42c3-a631-0c8c87a72944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f16f57-1a1d-46b6-990d-632dba09bdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f36a09-0393-41de-bcdb-77956a006509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c927a7-1b0e-4c55-b57a-d0b6c3bab8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ca1e7-eaf1-4fe2-8006-04d0a04aa957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ede97-677f-4d1a-8393-931c9306825f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f65b1-3c68-4c8a-8a56-f25f2a5ffcf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f5f2640-992f-4495-ac36-3be549480b50",
   "metadata": {},
   "source": [
    "## Testing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2a4b80-0d0f-4d4d-941f-7fd6a6d12600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, PretrainedConfig, CLIPTextModel, CLIPImageProcessor\n",
    "import diffusers\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    ControlNetModel,\n",
    "    DDPMScheduler,\n",
    "    StableDiffusionControlNetPipeline, \n",
    "    StableDiffusionControlNetImg2ImgPipeline,\n",
    "    UNet2DConditionModel,\n",
    "    UniPCMultistepScheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f667b87-9366-49b7-ba5e-f548c4fcb61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0a2b0-0edf-433c-9537-6c9d127a4883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "423a360f-4f1f-4899-8390-baee2c273a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet_img2img.StableDiffusionControlNetImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "pipeline = StableDiffusionControlNetImg2ImgPipeline(\n",
    "    vae=vae,\n",
    "    text_encoder=text_encoder,\n",
    "    tokenizer=tokenizer,\n",
    "    unet=unet,\n",
    "    controlnet=controlnet,\n",
    "    scheduler = noise_scheduler,\n",
    "    safety_checker = None,\n",
    "    feature_extractor = CLIPImageProcessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98420da-d797-41da-ab9f-5f9c5c1f76d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c24fc28c-dd73-4713-ab22-47060564b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd376e56-d7dc-47c3-95bd-699abb4ab6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd49d207-270f-4e7c-93ba-b56c6d6a0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-x4-upscaler\", subfolder=\"vae\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "541b7802-8655-4fcd-ab88-bd611db11b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder_cls = CLIPTextModel\n",
    "text_encoder_cls\n",
    "text_encoder = text_encoder_cls.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-x4-upscaler\", subfolder=\"text_encoder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7a3ae3-0a8a-4dc3-b4ee-adabc09b9d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-x4-upscaler\",\n",
    "    subfolder=\"tokenizer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e17bd87-83db-4133-9bc7-110196424b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-x4-upscaler\", subfolder=\"unet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da655a0c-567f-4d42-bc6e-52832af56718",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res_scheduler="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb3335a7-7bef-48d9-bcd9-e6320fff6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDPMScheduler.from_pretrained(\"stabilityai/stable-diffusion-x4-upscaler\", subfolder=\"scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ef567-d978-438b-b63f-3909eeafb93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a885b5-71a5-45a4-be33-b6b1ae2c000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet = ControlNetModel.from_unet(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd71a27-87b0-4c5c-9898-d979c37a9dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaf94f4f-b961-4cfd-89b0-946c9aac312f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ControlNetModel(\n",
       "  (conv_in): Conv2d(7, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (class_embedding): Embedding(1000, 1024)\n",
       "  (controlnet_cond_embedding): ControlNetConditioningEmbedding(\n",
       "    (conv_in): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (blocks): ModuleList(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): Conv2d(32, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): Conv2d(96, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (conv_out): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=512, out_features=4096, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=512, out_features=4096, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1024, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (norm2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (norm2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (controlnet_down_blocks): ModuleList(\n",
       "    (0-3): 4 x Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4-9): 6 x Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (10-11): 2 x Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (controlnet_mid_block): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (mid_block): UNetMidBlock2DCrossAttn(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Transformer2DModel(\n",
       "        (norm): GroupNorm(32, 1024, eps=1e-06, affine=True)\n",
       "        (proj_in): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.requires_grad_(False)\n",
    "unet.requires_grad_(False)\n",
    "text_encoder.requires_grad_(False)\n",
    "controlnet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5deb7417-bb74-4d17-be90-72b720aeb35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet.enable_gradient_checkpointing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55ab11-3a2a-4cb8-81c8-dccf0162ba60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfbdc3-3d47-444d-a4cf-ea4b981791a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae23349-b5c8-42ad-869c-9aa763b792c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9982bdc1-77b8-45bb-aabe-bbd85d8f6325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([262])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (1,))\n",
    "timesteps = timesteps.long()\n",
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d099255-3568-4eaa-a4bd-be8ffa535ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e49ba-79ff-480a-9493-d097ab1ba161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d58bee95-490b-408f-8ab2-78d60071a8fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_hidden_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m down_block_res_samples, mid_block_res_sample \u001b[38;5;241m=\u001b[39m controlnet(\n\u001b[1;32m      2\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m))\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mweight_dtype),\n\u001b[1;32m      3\u001b[0m     timesteps,\n\u001b[0;32m----> 4\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[43mencoder_hidden_states\u001b[49m,\n\u001b[1;32m      5\u001b[0m     controlnet_cond\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m))\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mweight_dtype),\n\u001b[1;32m      6\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     class_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint)\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_hidden_states' is not defined"
     ]
    }
   ],
   "source": [
    "down_block_res_samples, mid_block_res_sample = controlnet(\n",
    "    torch.zeros((1, 7, 32, 32)).to(dtype=weight_dtype),\n",
    "    timesteps,\n",
    "    encoder_hidden_states=encoder_hidden_states,\n",
    "    controlnet_cond=torch.zeros((1, 3, 256, 256)).to(dtype=weight_dtype),\n",
    "    return_dict=False,\n",
    "    class_labels = torch.zeros(1).to(dtype=torch.int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404a055-f8d2-4778-9570-ab7dcee64ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4bff8-f6a9-4c99-aa85-c632b5d8e908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c047e5-48c5-41db-bdd4-db421da597bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4da8c4-d1f0-424b-875c-730af89bb024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a80bc5-483f-44e7-b9ce-f4334e374e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42badb0-54d1-405b-ac9b-06af26447389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade13722-c6f7-4a88-af62-b5f6c9ea5227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29d0bc-48ad-4d48-8eb6-36aa4d97fc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7e9abd3-426a-454f-b0b4-22adfd1d3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet = ControlNetModel.from_unet(unet)\n",
    "#controlnet.conv_in = torch.nn.Sequential(torch.nn.Conv2d(4, 7, kernel_size=1, padding=0, stride=1, bias=False), controlnet.conv_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c22986-974c-491b-ad23-eceac91c6556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161f6d0-2333-4307-9a3c-c788f6b8d2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59423e6f-42dd-4f6a-98d9-ccad91a9b05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b6cda-6218-49ad-b3dd-8a0210f58bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6afa681-573d-4fca-8226-a8a0ad9a5f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa027b-8cba-4166-826d-5131081d2324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b7277-9f26-44bc-a52f-3d24f17e73ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b6675-a78f-4e33-be09-108989ac9507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf57cda-a514-4db2-9ad4-b30ce60648eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3eff93-0a9f-4ebb-9244-414af8917ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6af0b-1d91-4b6b-bb19-31ed72cbcdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f8e991f-0de1-4513-9628-97ad4c98b3b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UNet2DConditionModel.forward() missing 2 required positional arguments: 'timestep' and 'encoder_hidden_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: UNet2DConditionModel.forward() missing 2 required positional arguments: 'timestep' and 'encoder_hidden_states'"
     ]
    }
   ],
   "source": [
    "unet(torch.zeros(1, 7, 32, 32).to(dtype=weight_dtype), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbd2da-0817-4e71-bccd-a39a0fbe621d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e28b99-e3a1-4f92-8f13-878ef3d8bcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce69d4-06a8-4eff-b54e-6794bbdfc2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556da2b0-1c4b-45af-ad13-02a8f2257313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bed4ab-ad3a-41df-9213-e7dde7b57fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bafa9637-8457-4100-a9dd-0b28268850eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37e1e5-ef73-41d9-ac6e-8334ce90bb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c211ae19-10ef-4c06-bfdb-27586a03aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_class = bnb.optim.AdamW8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940ee70-cbd1-45ea-9f09-f804ce3469c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f83efef6-5fbf-486a-992f-5475083a87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_optimize = controlnet.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e05b80e8-b130-4ae5-97e0-ce0eed145c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "adam_weight_decay = 1e-2\n",
    "adam_epsilon = 1e-08\n",
    "optimizer = optimizer_class(\n",
    "        params_to_optimize,\n",
    "        lr=1e-5,\n",
    "        betas=(adam_beta1, adam_beta2),\n",
    "        weight_decay=adam_weight_decay,\n",
    "        eps=adam_epsilon,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11507430-dda3-4a44-87e9-ebb4e0560482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5484699a-2ed4-47fa-9dea-4162e5fe60b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc507db1-cf55-4321-8caa-f01eb5dc8a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb696594-3925-41c1-8b07-6e5cf8103c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "619c7222-4c48-4ea3-9220-90c72f3df5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd2-upscale/low_res_cat.png\"\n",
    "response = requests.get(url)\n",
    "low_res_img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "low_res_img = low_res_img.resize((128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da1e529-2d3a-47dc-94c1-fee78614dd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10cd73b8-f377-4773-bb03-893ff2eab0c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inp \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpil_to_tensor(low_res_img)\n\u001b[1;32m      2\u001b[0m inp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(inp, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m inp\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "inp = torchvision.transforms.functional.pil_to_tensor(low_res_img)\n",
    "inp = torch.unsqueeze(inp, 0)\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73da13-fcf0-447b-8dd5-20ae358f3c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554db86b-55a6-4843-945a-1b3480fbdbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb7b8e45-241c-45e9-89f2-a168b75d9e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 32, 32])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latents = vae.encode(torch.zeros((1, 3, 128, 128)).to(dtype=weight_dtype)).latent_dist.sample()\n",
    "latents = latents * vae.config.scaling_factor\n",
    "latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15f91f-97b6-44ab-a52d-14bdfa16f222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d046f4aa-18d4-40ca-86c4-d4e3d2d5329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = vae.decode(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49634599-7ea1-49c5-8725-2dbf641db094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908f2c5-64b6-4110-a260-888704710894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1580c7e-9818-4ebc-a9e9-302f3c9a96d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b1f02ca-16e2-4ba2-b9ce-6c16836b4009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 32, 32])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = vae.encode(torch.zeros((1, 3, 128, 128)).to(dtype=weight_dtype)).latent_dist.sample()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "226279c9-de22-444b-9dd6-99aceb826a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outt = vae.decode(torch.zeros((1, 4, 32, 32)).to(dtype=weight_dtype)).sample\n",
    "outt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb6878-fd7b-4ed3-aca8-592a07a840e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c413fc-a941-4e3a-9e88-81bbc08540bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee6728-e0a5-43f7-b81d-791ef95c894b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c19d23-0f1d-4960-92e7-cedc43ee7f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f3764b-6974-4537-8444-7343b61fc150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8406774c-8d5d-46e1-be58-5b049a9fe8a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m latents \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mencode(\u001b[43minp\u001b[49m\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mweight_dtype))\u001b[38;5;241m.\u001b[39mlatent_dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m      2\u001b[0m latents \u001b[38;5;241m=\u001b[39m latents \u001b[38;5;241m*\u001b[39m vae\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mscaling_factor\n\u001b[1;32m      3\u001b[0m latents\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inp' is not defined"
     ]
    }
   ],
   "source": [
    "latents = vae.encode(inp.to(dtype=weight_dtype)).latent_dist.sample()\n",
    "latents = latents * vae.config.scaling_factor\n",
    "latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b802a-4661-42d5-a933-ff8ed005e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = latents.shape[0]\n",
    "bsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a3993-8ba5-4db0-8798-e2ccd3c94856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765bc39-1d58-41e9-a045-5d05e28328a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn_like(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83437ef-5f6e-4b5a-a82c-0716fc21e7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45624342-feb4-499d-a001-9a1c6fe0969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,))\n",
    "timesteps = timesteps.long()\n",
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a5b1a-40ef-488f-a36a-32a6cb7e58ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df8bda-03e0-4888-804b-027f63c53015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb9659-cc94-49db-8438-64c1680ddb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d9c6e-8b50-4c70-a425-4ea1ccc6275b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87b12d-2dc2-497a-90a8-15b7002b497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "noisy_latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba85a8-b635-49a2-97c4-fcd2f412f912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12fdaedb-7847-4a63-9a8d-29a787ea950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-x4-upscaler\",\n",
    "    subfolder=\"tokenizer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ab6ca-3b5a-4f18-b3fe-9daaeff942e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311c3a6-7999-4a6a-9d15-bc3244e889cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [\"\"]\n",
    "inputs = tokenizer(\n",
    "    captions, max_length=tokenizer.model_max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "encoder_hidden_states = text_encoder(inputs.input_ids, return_dict=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f5fc9-e64d-4b3c-96b6-a03379fc1284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d2829-4718-4f67-86fa-a8fc6097188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet_image = torch.zeros((1, 3, 32, 32)).to(dtype=weight_dtype)\n",
    "controlnet_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee444745-4f38-400e-a5f0-96b9cb1c3c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6327a-54cc-45c7-8ff9-ec19a36bc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2f992-0137-4530-b358-861d06253a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654fc745-b629-4b5c-9440-f91ded4a12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros((1, 7, 32, 32)).to(dtype=weight_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f68ef4-4513-4bac-8d92-326a8bd77037",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = controlnet.conv_in(torch.zeros((1, 7, 32, 32)).to(dtype=weight_dtype)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e6e5c-53cf-4ae8-9e2f-c331d51e6516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b81c4e-b0c0-47bd-8ef3-514f3c957eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet_cond = controlnet.controlnet_cond_embedding(torch.zeros((1, 3, 256, 256)).to(dtype=weight_dtype))\n",
    "controlnet_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4d80f-4856-4603-b0e2-483f90d1e3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e39a9b-f94c-43e7-b567-6e423f7666cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5fadf8-ef02-4d50-b3f2-0f84fcb6d8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8336c5f-ef2d-4486-bcca-5b45b0117081",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf2378-cfdd-435c-8439-d675c9b0f4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963e20f-8116-406b-babe-ff57bf2b43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "down_block_res_samples, mid_block_res_sample = controlnet(\n",
    "    torch.zeros((1, 7, 32, 32)).to(dtype=weight_dtype),\n",
    "    timesteps,\n",
    "    encoder_hidden_states=encoder_hidden_states,\n",
    "    controlnet_cond=torch.zeros((1, 3, 256, 256)).to(dtype=weight_dtype),\n",
    "    return_dict=False,\n",
    "    class_labels = torch.zeros(1).to(dtype=torch.int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde97af-a60e-41d8-8205-76c6c1f62a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716947cf-0d17-49c6-8306-6aabd1f866d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5a34b-edf2-4844-8e68-6c44e9180e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534add1-19c1-45eb-84a0-939caa85ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = unet(\n",
    "    torch.zeros((1, 7, 32, 32)).to(dtype=weight_dtype),\n",
    "    timesteps,\n",
    "    encoder_hidden_states=encoder_hidden_states,\n",
    "    down_block_additional_residuals=[\n",
    "        sample.to(dtype=weight_dtype) for sample in down_block_res_samples\n",
    "    ],\n",
    "    mid_block_additional_residual=mid_block_res_sample.to(dtype=weight_dtype),\n",
    "    return_dict=False,\n",
    "    class_labels = torch.zeros(1).to(dtype=torch.int)\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f2c98-42cf-4a3b-a158-fabf93396cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c222f2-54d6-437f-9ad5-e396c8020da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa68c69-a845-463d-9d02-adb1c0361687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee573cbf-2264-4067-bd67-d095f9af9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = noise_scheduler.get_velocity(latents, noise, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e985215-a26f-4b89-8211-853a9f309039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a37ba9-4974-4690-9a24-8115143108fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5202f6-e8b1-4e56-a841-197b86c9b163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469080b4-fcfc-4483-82ef-6baf1dad36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777eab75-1d4f-4ad3-8fb8-b4446db7e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "lr_scheduler.step()\n",
    "optimizer.zero_grad(set_to_none=args.set_grads_to_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b259c71-dcf0-4714-9c40-52800c3fb58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac06980b-68cc-4985-b6d9-acfc4c463184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d3558-aac0-47ac-ae2f-2048b33277fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65bb8d0-f4ed-41d7-bb3f-183d63f60eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27ca00-42cc-4a76-9255-c43e1e728160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c82bf-e37f-454e-a8b0-b814a1ed5b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ee6e9-1209-4c72-a4ed-eb173f7e0521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ddd41-7f75-456f-8558-cf1aee0f1a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749f94d-1250-4eab-b92f-3d8e8e3aa73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9383e4b8-1409-4992-ac64-13293a489f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4bbc2-f922-409f-b6aa-7b07e4a022c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c5986-f03b-42fa-891b-680104bb0a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
